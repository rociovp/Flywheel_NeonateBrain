{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7782cbd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Download files from Flywheel\n",
    "# Written by David Parker - updated Oct 2022\n",
    "# Adapted by Lisa Bruckert Nov 2021\n",
    "# Adapted by Rocio Poblaciones Apr 2022\n",
    "\n",
    "\"\"\"\n",
    "Changelog:\n",
    "10/31/2022 - Parker\n",
    " - Added regular expression filter ability to analysis label\n",
    " - Added gear version filter to analysis search\n",
    " - reorganized code/ added blocks\n",
    " - removed API key references.\n",
    "\n",
    "\"\"\"\n",
    "import flywheel\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import pathvalidate as pv\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "System settings to be used through the script"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create a work directory in our local \"home\" directory\n",
    "# Example: work_dir = Path(Path.home()/'Documents/Flywheel_QCreport', platform='auto')\n",
    "work_dir = Path('//')\n",
    "# If it doesn't exist, create it\n",
    "if not work_dir.exists():\n",
    "    work_dir.mkdir(parents = True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Flywheel settings to be used through the script"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Set the project ID you wish to download from:\n",
    "project_id = '5eafb9fd788701016978097d'\n",
    "\n",
    "# Set the subject labels you wish to download from\n",
    "subject_ids_to_download = ['21346',]\n",
    "\n",
    "# Set the gear we're looking for\n",
    "# Example: gear = 'bids-freesurfer'\n",
    "gear = 'rtp-pipeline'\n",
    "\n",
    "# Set the version of the gear we're looking for\n",
    "# \"latest\" will use the latest version of the gear installed on the site.\n",
    "version = 'latest'\n",
    "\n",
    "# Set the regular expression to match analyses to.  Only\n",
    "# analyses with a label that matches this regular expression\n",
    "# will be downloaded.  Use regex101.com to validate regular  expressions\n",
    "# Use the string: r\".*\" to accept all labels\n",
    "analysis_label_regex = r\"example_regex\"\n",
    "aregex = re.compile(analysis_label_regex)\n",
    "\n",
    "\n",
    "#We create a list of files,must include the exact file names as is on FW\n",
    "file_name_list=['t1.nii.gz',\n",
    "               'CC_Mot_wbt_noEval_clean.tck',\n",
    "               'CC_Occ_wbt_noEval_clean.tck',\n",
    "               'CC_OrbFron_wbt_noEval_clean.tck',\n",
    "               'CC_PostPar_wbt_noEval_clean.tck',\n",
    "               'CC_SupFron_wbt_noEval_clean.tck',\n",
    "               'CC_SupPar_wbt_noEval_clean.tck',\n",
    "               'CC_Temp_wbt_noEval_clean.tck',\n",
    "               'CC_AntFron_wbt_noEval_clean.tck',\n",
    "               'RTP_fa.csv',\n",
    "               'RTP_ad.csv',\n",
    "               'RTP_rd.csv',\n",
    "                'RTP_md.csv',\n",
    "               'RTP_ad.csv',\n",
    "                'RTP_cl.csv',\n",
    "                'RTP_rd.csv',\n",
    "                'RTP_C2ROIad.csv',\n",
    "                'RTP_C2ROIcl.csv',\n",
    "                'RTP_C2ROImd.csv',\n",
    "                'RTP_C2ROIad.csv',\n",
    "                'RTP_C2ROIrd.csv',\n",
    "                'RTP_C2ROIfa.csv',\n",
    "                'CFMaj_wbt_noEval_clean.tck',\n",
    "                'CFMin_wbt_noEval_clean.tck',\n",
    "                'LAF_wbt_noEval_clean.tck',\n",
    "               'LATR_wbt_noEval_clean.tck',\n",
    "               'LCC_wbt_noEval_clean.tck','LCH_wbt_noEval_clean.tck','LCST_wbt_noEval_clean.tck',\n",
    "               'LICP_wbt_noEval_clean.tck','LIFOF_wbt_noEval_clean.tck','LILF_wbt_noEval_clean.tck',\n",
    "               'LSCP_wbt_noEval_clean.tck','LSLF_wbt_noEval_clean.tck','LUF_wbt_noEval_clean.tck',\n",
    "               'MCP_wbt_noEval_clean.tck','RAF_wbt_noEval_clean.tck','RATR_wbt_noEval_clean.tck',\n",
    "               'RCC_wbt_noEval_clean.tck','RCH_wbt_noEval_clean.tck','RCST_wbt_noEval_clean.tck',\n",
    "               'RICP_wbt_noEval_clean.tck','RIFOF_wbt_noEval_clean.tck', 'RILF_wbt_noEval_clean.tck',\n",
    "               'RSCP_wbt_noEval_clean.tck','RSLF_wbt_noEval_clean.tck',\n",
    "               'RUF_wbt_noEval_clean.tck','dwi.nii.gz','dwi_wmCsd_autolmax.mif']\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Initialize flywheel thingies"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'flywheel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/64/_65g23s53n91l8xz4jy_lyww0000gp/T/ipykernel_11797/2773648703.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0;31m# I recommend storing your API key as an environment variable and then referencing it this way\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0;31m# You can do this as:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 4\u001B[0;31m \u001B[0mfw\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mflywheel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mClient\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mos\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0menviron\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'UPENN_API'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      5\u001B[0m \u001B[0mproject\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfw\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_project\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mproject_id\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'flywheel' is not defined"
     ]
    }
   ],
   "source": [
    "# Project ID for PT_NeonateBrain\n",
    "# I recommend storing your API key as an environment variable and then referencing it this way\n",
    "# You can do this in bash:\n",
    "# export STAN_API=\"<my_api_key>\"\n",
    "# Before running this script.\n",
    "\n",
    "fw = flywheel.Client(os.environ['STAN_API'])\n",
    "project = fw.get_project(project_id)\n",
    "\n",
    "if version == \"latest\":\n",
    "    gears = fw.get_all_gears(filter=f\"gear.name={gear}\")\n",
    "    if not gears:\n",
    "        print(f'INVALID GEAR NAME {gear}')\n",
    "        raise Exception(\"Invalid gear name\")\n",
    "\n",
    "    version = gears[0].gear.version\n",
    "\n",
    "# Create a custom path for our project (we may run this on other projects in the future) and create if it doesn't exist\n",
    "project_path = pv.sanitize_filepath(work_dir/project.label)\n",
    "if not project_path.exists():\n",
    "    project_path.mkdir()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Perform the search and loop over the subjects specified"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# We can loop over sessions (and skip subjects), because the subject parent info is stored on the session if we need it,\n",
    "# AND the analysis of interest is stored on the session itself.\n",
    "for ses in tqdm(project.sessions.iter()):\n",
    "\n",
    "\n",
    "    # If subjects_ids_to_download is a list with some ids inside\n",
    "    # then lets only do those.\n",
    "    # If subject_ids_to_download is NOT False and ses_label IS inside subject_ids_to_download\n",
    "    # then do the process below\n",
    "    # else, continue\n",
    "\n",
    "    ses_label = ses.label\n",
    "    sub_label = ses.subject.label\n",
    "\n",
    "    if (subject_ids_to_download is not False) & (str(sub_label) not in subject_ids_to_download):\n",
    "        #print(\"Jumping \" + str(ses_label))\n",
    "        continue\n",
    "    else:\n",
    "        print(\"Analyzing Subject id: \" + str(ses_label) + \" Session id\" + str(sub_label))\n",
    "\n",
    "\n",
    "    # Make sure we have all our analysis since we got the session through an iterator, and not \"fw.get()'\n",
    "    ses = ses.reload()\n",
    "    analyses = ses.analyses\n",
    "\n",
    "    # If there are no analyses containers, we know that this gear was not run. Move on to the next session\n",
    "    if len(analyses) == 0:\n",
    "        continue\n",
    "\n",
    "    # Otherwise there are analyses containers\n",
    "    else:\n",
    "        print(f'{ses.label} has analysis')\n",
    "\n",
    "        # Check to see if any were generated by our gear\n",
    "        matches = [\n",
    "                    asys for asys in analyses if\n",
    "                    asys.gear_info.get('name') == gear\n",
    "                    and asys.gear_info.get('version')==version\n",
    "                    and aregex.findall(asys.label)\n",
    "                   ]\n",
    "\n",
    "        print(f'{len(matches)} matches in {[asys.label for asys in analyses]}')\n",
    "        # If there are no matches, the gear didn't run\n",
    "        if len(matches) == 0:\n",
    "            continue\n",
    "\n",
    "        # If there is one match, that's our target\n",
    "        elif len(matches) == 1:\n",
    "            match = matches[0]\n",
    "\n",
    "        # If there are more than one matches (due to reruns), take the most recent run.\n",
    "        # This behavior may be modified to whatever suits your needs\n",
    "        else:\n",
    "\n",
    "           # Loop through the analyses and first make sure we only look at successful runs\n",
    "            matches = [asys for asys in matches if asys.job.get('state')=='complete']\n",
    "            print(f'{len(matches)} completed matches')\n",
    "\n",
    "            # Now find the max run date (most recent), and extract the analysis that has that date.\n",
    "            last_run_date = max([asys.created for asys in matches])\n",
    "            last_run_analysis = [asys for asys in matches if asys.created == last_run_date]\n",
    "\n",
    "            # There should only be one exact match.  If there are two successful runs that happened at the same time,\n",
    "            # Something is strange...just take one at random.\n",
    "            match = last_run_analysis[0]\n",
    "\n",
    "        status = match.job.get('state')\n",
    "\n",
    "        # If the status is complete, look for the output file:\n",
    "        if status == 'complete':\n",
    "            # Put the download section within a \"try\" loop in case there are API errors downloading.\n",
    "            try:\n",
    "                # Reload the match and let's look at the files\n",
    "                match = match.reload()\n",
    "                files = match.files\n",
    "\n",
    "                # In case there are more files (there shouldn't be), find the one that's\n",
    "                # A zip archive.\n",
    "                if len(files) > 1:\n",
    "                    files = [f for f in files if f.mimetype == 'application/zip']\n",
    "\n",
    "                # Exctract the file object\n",
    "                file = files[0]\n",
    "                # Get it's name\n",
    "                fname = file.name\n",
    "                print(\"fname\")\n",
    "                print(fname)\n",
    "\n",
    "\n",
    "                # Get the zip members.  We're looking for one particular file called \"aseg.stats\", but the actual\n",
    "                # Directory may be different from subject to subject, as the parent directories have subject ID's in their name\n",
    "                zip_info = match.get_file_zip_info(fname)['members']\n",
    "\n",
    "                # We'll identify any strings that have this aseg.stats string in them\n",
    "                # Example: file_of_interest = [a['path'] for a in zip_info if '/aseg.stats' in a['path']]\n",
    "\n",
    "\n",
    "               #We loop over files using variable file_name that includes all elements in file_name_list\n",
    "\n",
    "                for file_name in file_name_list:\n",
    "                    file_of_interest = [a['path'] for a in zip_info if '/'+ file_name in a['path']]\n",
    "                    print(file_of_interest)\n",
    "                # If we found some (There should be one), set that as our file of interest.\n",
    "                    if len(file_of_interest) > 0:\n",
    "                        file_of_interest = file_of_interest[0]\n",
    "                    else:\n",
    "                        print(f'No File of Interest found for {sub_label} {ses_label} {match.label}' )\n",
    "                        continue\n",
    "\n",
    "\n",
    "                #We create a variable download_name with var file_name and sanitize name.\n",
    "                    download_name = Path(pv.sanitize_filename(f'{match.label}'+'_' + file_name))\n",
    "\n",
    "                    download_dir = pv.sanitize_filepath(project_path/sub_label)\n",
    "                    # Create the path\n",
    "                    if not download_dir.exists():\n",
    "                        download_dir.mkdir(parents=True)\n",
    "\n",
    "                    download_path = download_dir/download_name\n",
    "                    print('download_path')\n",
    "                    print(download_path)\n",
    "\n",
    "                # Download the file\n",
    "                #If we don't want to replace existing files use if not, if we want to replace them skip this step\n",
    "                    if not os.path.exists(download_path):\n",
    "                        print('downloading file')\n",
    "                        match.download_file_zip_member(fname, file_of_interest, download_path)\n",
    "                    else:\n",
    "                        print('File exists')\n",
    "\n",
    "\n",
    "            # Alert the user of any exceptions.\n",
    "            except Exception as e:\n",
    "                print('Error Downloading File')\n",
    "                print(e)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
